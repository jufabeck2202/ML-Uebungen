{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation mit Cross-Validation\n",
    "Um verschiede Verfahren und Parameter möglichst ohne die Gefahr des overfitting evaluieren zu können, steht man immer vor dem Problem: Mit welchen Daten trainiere ich meine Verfahren und mit welchen teste ich? Offensichtlich hängt das Ergebnis der Evaluation stark von der konkreten Auswahl des Test- bzw. Trainingsdatensatzes ab. \n",
    "\n",
    "Eine in der Literatur etablierte Methode der systematischen Evaluation ist Cross-Validation (Link: [Cross-Validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29)). Die grundlegende Idee des k-Fold  Cross-Validation (Link: [k-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#k-fold_cross-validation)) ist wie folgt: Die Gesamtmenge an Klassen-annotierten Datensätzen $T$ wird zufällig in $k$ gleich große Teilmengen (Folds) $T_1 \\dots T_k$ aufgeteilt. Es werden $k$ Testiteration $i_1 \\dots i_k$ durchgeführt. In jeder Iteration wird jeweils eine andere Teilmenge $T_i$ als Testdatensatz und die restlichen Daten $T \\setminus T_i$ als Trainingsdatensatz verwendet. Als Gesamt Ergebniss der Cross-Validation wird der Mittelwert der Genauigkeiten der einzelnen Iteration herangezogen. \n",
    "\n",
    "Weitere Verfahren sind bspw. Holdout (Link: [Holdout](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#Holdout_method)), Nested cross-validation (Link: [Nested cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#Nested_cross-validation)) etc.\n",
    "\n",
    "<figure>\n",
    "<img src=\"./Figures/k-fold-cross-validation.png\" alt=\"drawing\" style=\"width:600px;\">\n",
    "    <figcaption>k-fold Cross Validation, Quelle: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/K-fold_cross_validation_EN.svg/500px-K-fold_cross_validation_EN.svg.png\n",
    "        </figcaption>\n",
    "</figure>\n",
    "\n",
    "Erweitern Sie Ihre Implementierung des KNN-Algorithmus aus dem vorherigen Teil um das <b>k-fold Cross-Validation</b> Verfahren. Wählen Sie hierbei einen geeigneten Wert für die Anzahl der k-folds, bzw. experimentieren Sie mit verschiedenen Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = './Data/original_titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE, header=0)\n",
    "\n",
    "def prepareData(df):\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    \n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    \n",
    "    \n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    \n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    return df\n",
    "\n",
    "df = prepareData(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalice data column \n",
    "def normalize_colummn(feature):\n",
    "    mean = feature.mean()\n",
    "    std = feature.std()\n",
    "    feature_array = feature.to_numpy()\n",
    "    \n",
    "    for index in range(len(feature_array)):\n",
    "        feature_array[index] = (float(feature_array[index]) - mean) / std\n",
    "        #print(float(feature_array[index]) - mean, feature_array[index])\n",
    "    return pd.DataFrame(feature_array)\n",
    "\n",
    "#normalize Age and Fare    \n",
    "def normalize(df):\n",
    "    new_dataFrame = df.copy()\n",
    "    new_dataFrame.assign(Age=normalize_colummn(new_dataFrame.Age))\n",
    "    new_dataFrame.assign(Fare=normalize_colummn(new_dataFrame.Fare))\n",
    "    return  new_dataFrame # TODO implement\n",
    "\n",
    "#normalize data\n",
    "df_norm = normalize(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create FeatureVectore by Sex Age and Pclass\n",
    "def extractFeatureVector(row):\n",
    "    if row.Sex == \"male\":\n",
    "        sex = 1\n",
    "    else:\n",
    "        sex = 0\n",
    "    return np.array([sex, row.Age, row.Pclass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    \n",
    "    def __init__(self, k, distmethod, data, parts):\n",
    "        print(\"k:\",k,\"parts:\",parts)\n",
    "        self.k = k\n",
    "        self.data = data\n",
    "        self.parts = parts\n",
    "        self.count = 0\n",
    "        self.acc = []\n",
    "        self.distmethod = distmethod\n",
    "        \n",
    "        #execute cross validation\n",
    "        for i in range(self.parts):\n",
    "            self.fit()\n",
    "            self.acc.append(self.getAcc())\n",
    "            print(\"%.2f\" % ((100/self.parts)*(i+1)), \"% :\",self.acc[-1])\n",
    "            \n",
    "        print(\"result:\",np.mean(self.acc))\n",
    "        \n",
    "    def distance(self, vector1,vector2):\n",
    "        if self.distmethod == 0:\n",
    "            return self._distance_manhattan(vector1,vector2)\n",
    "        elif self.distmethod == 1:\n",
    "            return self._distance_euklidischer(vector1,vector2)\n",
    "    \n",
    "    def _distance_manhattan(self, vector1,vector2):        \n",
    "        #Manhattan\n",
    "        vector1 = np.array(vector1)\n",
    "        vector2 = np.array(vector2)\n",
    "        sub_array = []\n",
    "        for i in range(len(vector1)):\n",
    "            sub_array.append(np.absolute(vector1[i] - vector2[i]))\n",
    "\n",
    "        return np.sum(sub_array)\n",
    "    \n",
    "    def _distance_euklidischer(self, vector1,vector2):\n",
    "        #Euklidischer \n",
    "        vector1 = np.array(vector1)\n",
    "        vector2 = np.array(vector2)\n",
    "        sub_array = []\n",
    "        for i in range(len(vector1)):\n",
    "            sub_array.append(math.pow(vector1[i] - vector2[i],2))\n",
    "\n",
    "        sum_of_all = np.sum(sub_array)\n",
    "        \n",
    "        return math.sqrt(sum_of_all)\n",
    "    \n",
    "    def fit(self):\n",
    "        self.trainData = []\n",
    "        self.trainLabel = []\n",
    "        \n",
    "        self.cross_validation()\n",
    "        \n",
    "        for index, row in self.train.iterrows():\n",
    "            self.trainData.append(extractFeatureVector(row))\n",
    "            self.trainLabel.append(row.Survived)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        dis_to_x = []\n",
    "        for i in range(len(self.trainData)):\n",
    "            dis_to_x.append({\"d\" : self.distance(x,self.trainData[i]), \"s\":self.trainLabel[i] })\n",
    "        sorted_dis = sorted(dis_to_x, key = lambda i: i['d'])\n",
    "        k_sorted =  sorted_dis[:self.k]\n",
    "        \n",
    "        k_results = []\n",
    "\n",
    "        for i in k_sorted:\n",
    "            k_results.append(i[\"s\"])\n",
    "        return max(k_results,key=k_results.count)\n",
    "    \n",
    "    def getAcc(self):\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for index, row in self.test.iterrows():\n",
    "            predicted = self.predict(extractFeatureVector(row))\n",
    "            actual = row[\"Survived\"]\n",
    "\n",
    "            if predicted == 1:\n",
    "                if actual == 1:\n",
    "                    tp += 1\n",
    "                else:  \n",
    "                    fp += 1\n",
    "            else:\n",
    "                if actual == 1:\n",
    "                    fn += 1\n",
    "                else: \n",
    "                    tn += 1\n",
    "\n",
    "\n",
    "        return (tp + tn) / (tp + tn + fp +fn)\n",
    "    \n",
    "    def cross_validation(self):\n",
    "        #split data in parts pieces\n",
    "        split = np.array_split(self.data, self.parts)\n",
    "        k_split = split.copy()\n",
    "        \n",
    "        #get test data\n",
    "        self.test = k_split[self.count]\n",
    "        \n",
    "        #remove test data form parts\n",
    "        del k_split[self.count] \n",
    "        \n",
    "        #get train data\n",
    "        self.train =  pd.concat(k_split)\n",
    "        \n",
    "        self.count += 1\n",
    "        \n",
    "        if self.count > self.parts-1:\n",
    "            self.count = 0\n",
    "           \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 3 parts: 3\n",
      "33.33 % : 0.8421052631578947\n",
      "66.67 % : 0.8279816513761468\n",
      "100.00 % : 0.8256880733944955\n",
      "result: 0.8319249959761789\n",
      "k: 10 parts: 3\n",
      "33.33 % : 0.8215102974828375\n",
      "66.67 % : 0.8119266055045872\n",
      "100.00 % : 0.841743119266055\n",
      "result: 0.8250600074178266\n",
      "k: 20 parts: 3\n",
      "33.33 % : 0.8077803203661327\n",
      "66.67 % : 0.8302752293577982\n",
      "100.00 % : 0.8142201834862385\n",
      "result: 0.8174252444033897\n",
      "k: 3 parts: 10\n",
      "10.00 % : 0.8473282442748091\n",
      "20.00 % : 0.8091603053435115\n",
      "30.00 % : 0.8549618320610687\n",
      "40.00 % : 0.8625954198473282\n",
      "50.00 % : 0.7862595419847328\n",
      "60.00 % : 0.8396946564885496\n",
      "70.00 % : 0.8320610687022901\n",
      "80.00 % : 0.8091603053435115\n",
      "90.00 % : 0.8320610687022901\n",
      "100.00 % : 0.7538461538461538\n",
      "result: 0.8227128596594246\n",
      "k: 10 parts: 10\n",
      "10.00 % : 0.9007633587786259\n",
      "20.00 % : 0.8625954198473282\n",
      "30.00 % : 0.7557251908396947\n",
      "40.00 % : 0.8320610687022901\n",
      "50.00 % : 0.7938931297709924\n",
      "60.00 % : 0.8320610687022901\n",
      "70.00 % : 0.816793893129771\n",
      "80.00 % : 0.7938931297709924\n",
      "90.00 % : 0.8778625954198473\n",
      "100.00 % : 0.8692307692307693\n",
      "result: 0.83348796241926\n",
      "k: 20 parts: 10\n",
      "10.00 % : 0.8473282442748091\n",
      "20.00 % : 0.8244274809160306\n",
      "30.00 % : 0.8396946564885496\n",
      "40.00 % : 0.8549618320610687\n",
      "50.00 % : 0.8244274809160306\n",
      "60.00 % : 0.8396946564885496\n",
      "70.00 % : 0.816793893129771\n",
      "80.00 % : 0.8320610687022901\n",
      "90.00 % : 0.8549618320610687\n",
      "100.00 % : 0.8692307692307693\n",
      "result: 0.8403581914268937\n",
      "k: 3 parts: 20\n",
      "5.00 % : 0.8181818181818182\n",
      "10.00 % : 0.8636363636363636\n",
      "15.00 % : 0.8787878787878788\n",
      "20.00 % : 0.8787878787878788\n",
      "25.00 % : 0.7878787878787878\n",
      "30.00 % : 0.8333333333333334\n",
      "35.00 % : 0.8484848484848485\n",
      "40.00 % : 0.8636363636363636\n",
      "45.00 % : 0.8787878787878788\n",
      "50.00 % : 0.8923076923076924\n",
      "55.00 % : 0.8153846153846154\n",
      "60.00 % : 0.7846153846153846\n",
      "65.00 % : 0.8307692307692308\n",
      "70.00 % : 0.7538461538461538\n",
      "75.00 % : 0.7846153846153846\n",
      "80.00 % : 0.7692307692307693\n",
      "85.00 % : 0.8\n",
      "90.00 % : 0.8615384615384616\n",
      "95.00 % : 0.8615384615384616\n",
      "100.00 % : 0.8\n",
      "result: 0.8302680652680653\n",
      "k: 10 parts: 20\n",
      "5.00 % : 0.8181818181818182\n",
      "10.00 % : 0.7575757575757576\n",
      "15.00 % : 0.7727272727272727\n",
      "20.00 % : 0.9090909090909091\n",
      "25.00 % : 0.803030303030303\n",
      "30.00 % : 0.803030303030303\n",
      "35.00 % : 0.7727272727272727\n",
      "40.00 % : 0.9090909090909091\n",
      "45.00 % : 0.8333333333333334\n",
      "50.00 % : 0.8153846153846154\n",
      "55.00 % : 0.8153846153846154\n",
      "60.00 % : 0.8153846153846154\n",
      "65.00 % : 0.8923076923076924\n",
      "70.00 % : 0.8153846153846154\n",
      "75.00 % : 0.8153846153846154\n",
      "80.00 % : 0.8769230769230769\n",
      "85.00 % : 0.8461538461538461\n",
      "90.00 % : 0.7846153846153846\n",
      "95.00 % : 0.9076923076923077\n",
      "100.00 % : 0.8307692307692308\n",
      "result: 0.8297086247086247\n",
      "k: 20 parts: 20\n",
      "5.00 % : 0.803030303030303\n",
      "10.00 % : 0.8333333333333334\n",
      "15.00 % : 0.8181818181818182\n",
      "20.00 % : 0.8181818181818182\n",
      "25.00 % : 0.8787878787878788\n",
      "30.00 % : 0.7575757575757576\n",
      "35.00 % : 0.8939393939393939\n",
      "40.00 % : 0.803030303030303\n",
      "45.00 % : 0.8939393939393939\n",
      "50.00 % : 0.8307692307692308\n",
      "55.00 % : 0.8153846153846154\n",
      "60.00 % : 0.8153846153846154\n",
      "65.00 % : 0.8\n",
      "70.00 % : 0.8153846153846154\n",
      "75.00 % : 0.8\n",
      "80.00 % : 0.8307692307692308\n",
      "85.00 % : 0.8153846153846154\n",
      "90.00 % : 0.8923076923076924\n",
      "95.00 % : 0.7846153846153846\n",
      "100.00 % : 0.9076923076923077\n",
      "result: 0.8303846153846154\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(3, 1, df_norm.sample(frac=1) , 3)\n",
    "knn = KNN(10, 1, df_norm.sample(frac=1) , 3)\n",
    "knn = KNN(20, 1, df_norm.sample(frac=1) , 3)\n",
    "knn = KNN(3, 1, df_norm.sample(frac=1) , 10)\n",
    "knn = KNN(10, 1, df_norm.sample(frac=1) , 10)\n",
    "knn = KNN(20, 1, df_norm.sample(frac=1) , 10)\n",
    "knn = KNN(3, 1, df_norm.sample(frac=1) , 20)\n",
    "knn = KNN(10, 1, df_norm.sample(frac=1) , 20)\n",
    "knn = KNN(20, 1, df_norm.sample(frac=1) , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
