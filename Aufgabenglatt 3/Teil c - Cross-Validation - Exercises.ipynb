{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation mit Cross-Validation\n",
    "Um verschiede Verfahren und Parameter möglichst ohne die Gefahr des overfitting evaluieren zu können, steht man immer vor dem Problem: Mit welchen Daten trainiere ich meine Verfahren und mit welchen teste ich? Offensichtlich hängt das Ergebnis der Evaluation stark von der konkreten Auswahl des Test- bzw. Trainingsdatensatzes ab. \n",
    "\n",
    "Eine in der Literatur etablierte Methode der systematischen Evaluation ist Cross-Validation (Link: [Cross-Validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29)). Die grundlegende Idee des k-Fold  Cross-Validation (Link: [k-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#k-fold_cross-validation)) ist wie folgt: Die Gesamtmenge an Klassen-annotierten Datensätzen $T$ wird zufällig in $k$ gleich große Teilmengen (Folds) $T_1 \\dots T_k$ aufgeteilt. Es werden $k$ Testiteration $i_1 \\dots i_k$ durchgeführt. In jeder Iteration wird jeweils eine andere Teilmenge $T_i$ als Testdatensatz und die restlichen Daten $T \\setminus T_i$ als Trainingsdatensatz verwendet. Als Gesamt Ergebniss der Cross-Validation wird der Mittelwert der Genauigkeiten der einzelnen Iteration herangezogen. \n",
    "\n",
    "Weitere Verfahren sind bspw. Holdout (Link: [Holdout](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#Holdout_method)), Nested cross-validation (Link: [Nested cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#Nested_cross-validation)) etc.\n",
    "\n",
    "<figure>\n",
    "<img src=\"./Figures/k-fold-cross-validation.png\" alt=\"drawing\" style=\"width:600px;\">\n",
    "    <figcaption>k-fold Cross Validation, Quelle: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/K-fold_cross_validation_EN.svg/500px-K-fold_cross_validation_EN.svg.png\n",
    "        </figcaption>\n",
    "</figure>\n",
    "\n",
    "Erweitern Sie Ihre Implementierung des KNN-Algorithmus aus dem vorherigen Teil um das <b>k-fold Cross-Validation</b> Verfahren. Wählen Sie hierbei einen geeigneten Wert für die Anzahl der k-folds, bzw. experimentieren Sie mit verschiedenen Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = './Data/original_titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE, header=0)\n",
    "\n",
    "def prepareData(df):\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 0)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    \n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"male\")   &(df.Survived == 1)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    \n",
    "    \n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 0)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    \n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==1)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==1), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==2)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==2), \"Age\"].mean()\n",
    "    df.loc[(((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==3)) & df.Age.isnull(),\"Age\"] =  df.loc[((df.Sex == \"female\") &(df.Survived == 1)) & (df.Pclass==3), \"Age\"].mean()\n",
    "    return df\n",
    "\n",
    "df = prepareData(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_colummn(feature):\n",
    "    mean = feature.mean()\n",
    "    std = feature.std()\n",
    "    feature_array = feature.to_numpy()\n",
    "    \n",
    "    for index in range(len(feature_array)):\n",
    "        feature_array[index] = (float(feature_array[index]) - mean) / std\n",
    "        #print(float(feature_array[index]) - mean, feature_array[index])\n",
    "    return pd.DataFrame(feature_array)\n",
    "\n",
    "    \n",
    "def normalize(df):\n",
    "    new_dataFrame = df.copy()\n",
    "    new_dataFrame.assign(Age=normalize_colummn(new_dataFrame.Age))\n",
    "    new_dataFrame.assign(Fare=normalize_colummn(new_dataFrame.Fare))\n",
    "    return  new_dataFrame # TODO implement\n",
    "\n",
    "df_norm = normalize(df) # TODO : implement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatureVector(row):\n",
    "    # TODO : implement\n",
    "    return np.array([row.Fare, row.Age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    \n",
    "    def __init__(self, k, data, parts):\n",
    "        print(\"k:\",k,\"parts:\",parts)\n",
    "        self.k = k\n",
    "        self.data = data\n",
    "        self.parts = parts\n",
    "        self.count = 0\n",
    "        self.acc = []\n",
    "        \n",
    "        for i in range(self.parts):\n",
    "            self.fit()\n",
    "            self.acc.append(self.getAcc())\n",
    "            print(((100/self.parts)*(i+1)), \"% :\",self.acc[-1])\n",
    "            \n",
    "        print(\"result:\",np.mean(self.acc))\n",
    "        \n",
    "    def distance(self, vector1,vector2):\n",
    "        #Manhattan\n",
    "        vector1 = np.array(vector1)\n",
    "        vector2 = np.array(vector2)\n",
    "        sub_array = []\n",
    "        for i in range(len(vector1)):\n",
    "            sub_array.append(np.absolute(vector1[i] - vector2[i]))\n",
    "\n",
    "        return np.sum(sub_array)\n",
    "    \n",
    "    \n",
    "    def fit(self):\n",
    "        self.trainData = []\n",
    "        self.trainLabel = []\n",
    "        \n",
    "        self.cross_validation()\n",
    "        \n",
    "        for index, row in self.train.iterrows():\n",
    "            self.trainData.append(extractFeatureVector(row))\n",
    "            self.trainLabel.append(row.Survived)\n",
    "        \n",
    "        # TODO: implement\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        dis_to_x = []\n",
    "        for i in range(len(self.trainData)):\n",
    "            dis_to_x.append({\"d\" : self.distance(x,self.trainData[i]), \"s\":self.trainLabel[i] })\n",
    "        sorted_dis = sorted(dis_to_x, key = lambda i: i['d'])\n",
    "        k_sorted =  sorted_dis[:self.k]\n",
    "        \n",
    "        k_results = []\n",
    "\n",
    "        for i in k_sorted:\n",
    "            k_results.append(i[\"s\"])\n",
    "        return max(k_results,key=k_results.count)\n",
    "    \n",
    "    def getAcc(self):\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for index, row in self.test.iterrows():\n",
    "            predicted = self.predict(extractFeatureVector(row))\n",
    "            actual = row[\"Survived\"]\n",
    "\n",
    "            if predicted == 1:\n",
    "                if actual == 1:\n",
    "                    tp += 1\n",
    "                else:  \n",
    "                    fp += 1\n",
    "            else:\n",
    "                if actual == 1:\n",
    "                    fn += 1\n",
    "                else: \n",
    "                    tn += 1\n",
    "\n",
    "\n",
    "        return (tp + tn) / (tp + tn + fp +fn)\n",
    "    \n",
    "    def cross_validation(self):\n",
    "        split = np.array_split(self.data, self.parts)\n",
    "        k_split = split.copy()\n",
    "        \n",
    "        self.test = k_split[self.count]\n",
    "        \n",
    "        #np.delete(k_split, self.count)\n",
    "        del k_split[self.count] \n",
    "        self.train =  pd.concat(k_split)\n",
    "        \n",
    "        self.count += 1\n",
    "        \n",
    "        if self.count > self.parts-1:\n",
    "            self.count = 0\n",
    "           \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 3 parts: 3\n",
      "33.333333333333336 % : 0.6956521739130435\n",
      "66.66666666666667 % : 0.6330275229357798\n",
      "100.0 % : 0.6628440366972477\n",
      "result: 0.663841244515357\n",
      "k: 10 parts: 3\n",
      "33.333333333333336 % : 0.6544622425629291\n",
      "66.66666666666667 % : 0.7224770642201835\n",
      "100.0 % : 0.7178899082568807\n",
      "result: 0.6982764050133311\n",
      "k: 20 parts: 3\n",
      "33.333333333333336 % : 0.6842105263157895\n",
      "66.66666666666667 % : 0.731651376146789\n",
      "100.0 % : 0.7178899082568807\n",
      "result: 0.7112506035731531\n",
      "k: 3 parts: 10\n",
      "10.0 % : 0.7175572519083969\n",
      "20.0 % : 0.6412213740458015\n",
      "30.0 % : 0.6335877862595419\n",
      "40.0 % : 0.6412213740458015\n",
      "50.0 % : 0.6183206106870229\n",
      "60.0 % : 0.6335877862595419\n",
      "70.0 % : 0.6793893129770993\n",
      "80.0 % : 0.6717557251908397\n",
      "90.0 % : 0.6793893129770993\n",
      "100.0 % : 0.7076923076923077\n",
      "result: 0.6623722842043451\n",
      "k: 10 parts: 10\n",
      "10.0 % : 0.6870229007633588\n",
      "20.0 % : 0.7633587786259542\n",
      "30.0 % : 0.6717557251908397\n",
      "40.0 % : 0.6946564885496184\n",
      "50.0 % : 0.6946564885496184\n",
      "60.0 % : 0.7022900763358778\n",
      "70.0 % : 0.7175572519083969\n",
      "80.0 % : 0.6946564885496184\n",
      "90.0 % : 0.7099236641221374\n",
      "100.0 % : 0.6923076923076923\n",
      "result: 0.7028185554903112\n",
      "k: 20 parts: 10\n",
      "10.0 % : 0.7404580152671756\n",
      "20.0 % : 0.648854961832061\n",
      "30.0 % : 0.6717557251908397\n",
      "40.0 % : 0.6793893129770993\n",
      "50.0 % : 0.7251908396946565\n",
      "60.0 % : 0.7022900763358778\n",
      "70.0 % : 0.7862595419847328\n",
      "80.0 % : 0.6641221374045801\n",
      "90.0 % : 0.6946564885496184\n",
      "100.0 % : 0.7615384615384615\n",
      "result: 0.7074515560775103\n",
      "k: 3 parts: 20\n",
      "5.0 % : 0.6818181818181818\n",
      "10.0 % : 0.7575757575757576\n",
      "15.0 % : 0.7878787878787878\n",
      "20.0 % : 0.6363636363636364\n",
      "25.0 % : 0.6666666666666666\n",
      "30.0 % : 0.7727272727272727\n",
      "35.0 % : 0.7727272727272727\n",
      "40.0 % : 0.6666666666666666\n",
      "45.0 % : 0.7121212121212122\n",
      "50.0 % : 0.6461538461538462\n",
      "55.0 % : 0.6153846153846154\n",
      "60.0 % : 0.7846153846153846\n",
      "65.0 % : 0.676923076923077\n",
      "70.0 % : 0.676923076923077\n",
      "75.0 % : 0.6\n",
      "80.0 % : 0.7538461538461538\n",
      "85.0 % : 0.6307692307692307\n",
      "90.0 % : 0.6615384615384615\n",
      "95.0 % : 0.7538461538461538\n",
      "100.0 % : 0.5692307692307692\n",
      "result: 0.6911888111888111\n",
      "k: 10 parts: 20\n",
      "5.0 % : 0.7121212121212122\n",
      "10.0 % : 0.7272727272727273\n",
      "15.0 % : 0.7575757575757576\n",
      "20.0 % : 0.7121212121212122\n",
      "25.0 % : 0.7878787878787878\n",
      "30.0 % : 0.7272727272727273\n",
      "35.0 % : 0.6666666666666666\n",
      "40.0 % : 0.7121212121212122\n",
      "45.0 % : 0.6363636363636364\n",
      "50.0 % : 0.7846153846153846\n",
      "55.0 % : 0.7230769230769231\n",
      "60.0 % : 0.7230769230769231\n",
      "65.0 % : 0.6461538461538462\n",
      "70.0 % : 0.7384615384615385\n",
      "75.0 % : 0.6461538461538462\n",
      "80.0 % : 0.7230769230769231\n",
      "85.0 % : 0.676923076923077\n",
      "90.0 % : 0.7384615384615385\n",
      "95.0 % : 0.7230769230769231\n",
      "100.0 % : 0.676923076923077\n",
      "result: 0.7119696969696969\n",
      "k: 20 parts: 20\n",
      "5.0 % : 0.6818181818181818\n",
      "10.0 % : 0.7424242424242424\n",
      "15.0 % : 0.6515151515151515\n",
      "20.0 % : 0.6666666666666666\n",
      "25.0 % : 0.6666666666666666\n",
      "30.0 % : 0.7424242424242424\n",
      "35.0 % : 0.7121212121212122\n",
      "40.0 % : 0.7424242424242424\n",
      "45.0 % : 0.5606060606060606\n",
      "50.0 % : 0.7846153846153846\n",
      "55.0 % : 0.7538461538461538\n",
      "60.0 % : 0.7692307692307693\n",
      "65.0 % : 0.7076923076923077\n",
      "70.0 % : 0.7076923076923077\n",
      "75.0 % : 0.6923076923076923\n",
      "80.0 % : 0.6923076923076923\n",
      "85.0 % : 0.7384615384615385\n",
      "90.0 % : 0.7384615384615385\n",
      "95.0 % : 0.6307692307692307\n",
      "100.0 % : 0.7076923076923077\n",
      "result: 0.7044871794871795\n"
     ]
    }
   ],
   "source": [
    "knn = KNN(3, df_norm.sample(frac=1) , 3)\n",
    "knn = KNN(10, df_norm.sample(frac=1) , 3)\n",
    "knn = KNN(20, df_norm.sample(frac=1) , 3)\n",
    "knn = KNN(3, df_norm.sample(frac=1) , 10)\n",
    "knn = KNN(10, df_norm.sample(frac=1) , 10)\n",
    "knn = KNN(20, df_norm.sample(frac=1) , 10)\n",
    "knn = KNN(3, df_norm.sample(frac=1) , 20)\n",
    "knn = KNN(10, df_norm.sample(frac=1) , 20)\n",
    "knn = KNN(20, df_norm.sample(frac=1) , 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
